{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from PreprocessData import *\n",
    "\n",
    "from transformers import LongformerForSequenceClassification, LongformerTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         RT @2014WorIdCup: Argentina vs Belgium\\n\\nWho ...\n",
       "1         @elijahman_ time to focus on Belgium winning t...\n",
       "2         RT @FIFAWorldCup: GLOBAL STADIUM: #Joinin with...\n",
       "3         RT @CatholicNewsSvc: #PopeFrancis. Uh-oh. Arge...\n",
       "4         RT @soccerdotcom: If he scores vs #BEL we'll a...\n",
       "                                ...                        \n",
       "313798    RT @2014WC_Brazil: This is the first time in W...\n",
       "313799    RT @Footy___Girls: Lovely Celebration  #ARG\\n ...\n",
       "313800    It's not like I hate the country or anything, ...\n",
       "313801    RT @UtdIndonesiaBDG: Yah gugur, gutted couldn'...\n",
       "313802                   Can't wait for Argentina to go out\n",
       "Name: Tweet, Length: 313803, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_path = 'C:\\\\Users\\\\user\\\\Programming\\\\Git\\\\challenge_data\\\\train_tweets\\\\ArgentinaBelgium72.csv'\n",
    "\n",
    "df = pd.read_csv(train_file_path)\n",
    "pd.save(df['Tweet'])\n",
    "# df = pd.concat([df[:10], df[20000:20010]], axis=0)\n",
    "# df = df[['PeriodID', 'EventType', 'Tweet']]\n",
    "\n",
    "# # Apply preprocessing to each tweet\n",
    "# df['Tweet'] = df['Tweet'].apply(preprocess_text)\n",
    "# print(\"1: \", df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:         PeriodID  EventType                                              Tweet\n",
      "0             0          0  [0, 9713, 45155, 808, 21033, 29480, 1342, 1243...\n",
      "1             0          0  [0, 523, 44303, 397, 1215, 86, 1056, 12138, 57...\n",
      "2             0          0  [0, 9713, 45783, 1584, 39949, 21033, 720, 4773...\n",
      "3             0          0  [0, 9713, 31420, 12589, 4651, 7485, 36940, 349...\n",
      "4             0          0  [0, 9713, 4191, 33369, 175, 1471, 748, 12138, ...\n",
      "5             0          0  [0, 9713, 4191, 33369, 175, 1471, 748, 12138, ...\n",
      "6             0          0  [0, 298, 9877, 29480, 1342, 1243, 2217, 74, 15...\n",
      "7             0          0  [0, 11018, 29480, 1342, 1243, 748, 12138, 571,...\n",
      "8             0          0  [0, 267, 338, 20614, 329, 33976, 101, 29480, 1...\n",
      "9             0          0  [0, 12963, 600, 4157, 12138, 571, 4031, 4108, ...\n",
      "20000         9          1  [0, 9713, 21179, 282, 25484, 885, 438, 4401, 6...\n",
      "20001         9          1  [0, 9713, 22053, 438, 3314, 29480, 1342, 1243,...\n",
      "20002         9          1  [0, 9713, 13418, 6695, 607, 5, 21381, 11107, 1...\n",
      "20003         9          1  [0, 9713, 22053, 438, 3314, 29480, 1342, 1243,...\n",
      "20004         9          1  [0, 9713, 3023, 139, 1215, 40693, 1215, 1747, ...\n",
      "20005         9          1  [0, 2716, 213, 905, 213, 29480, 1342, 1243, 16...\n",
      "20006         9          1  [0, 571, 19864, 821, 7043, 219, 748, 29480, 13...\n",
      "20007         9          1      [0, 2977, 12138, 449, 7474, 3785, 2, 1, 1, 1]\n",
      "20008         9          1  [0, 20982, 1034, 29480, 1342, 1243, 339, 914, ...\n",
      "20009         9          1  [0, 9713, 29227, 1506, 8310, 4494, 3144, 3055,...\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the 'Tweet' column and pad/truncate to length l\n",
    "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "l = 10\n",
    "def tokenize_tweet(tweet):\n",
    "    tokens = tokenizer.encode(tweet, truncation=True, padding=\"max_length\", max_length=l, add_special_tokens=True)\n",
    "    return tokens\n",
    "df['Tweet'] = df['Tweet'].apply(tokenize_tweet)\n",
    "print(\"2: \", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3:     EventType  PeriodID                                              Tweet\n",
      "0          0         0  [0, 9713, 45155, 808, 21033, 29480, 1342, 1243...\n",
      "1          1         9  [0, 9713, 21179, 282, 25484, 885, 438, 4401, 6...\n"
     ]
    }
   ],
   "source": [
    "df_g = df.groupby(['EventType','PeriodID'])['Tweet'].apply(list).reset_index()\n",
    "df_g['Tweet'] = df_g['Tweet'].apply(lambda x: list(itertools.chain.from_iterable(x)))\n",
    "print(\"3: \", df_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4:      EventType  PeriodID                                  Tweet\n",
      "0           0         0    [0, 9713, 45155, 808, 21033, 29480]\n",
      "1           0         0           [1342, 1243, 748, 2, 0, 523]\n",
      "2           0         0    [44303, 397, 1215, 86, 1056, 12138]\n",
      "3           0         0         [571, 2, 0, 9713, 45783, 1584]\n",
      "4           0         0     [39949, 21033, 720, 4773, 1962, 2]\n",
      "5           0         0    [0, 9713, 31420, 12589, 4651, 7485]\n",
      "6           0         0        [36940, 3495, 4550, 2, 0, 9713]\n",
      "7           0         0   [4191, 33369, 175, 1471, 748, 12138]\n",
      "8           0         0         [157, 2, 0, 9713, 4191, 33369]\n",
      "9           0         0        [175, 1471, 748, 12138, 157, 2]\n",
      "10          0         0      [0, 298, 9877, 29480, 1342, 1243]\n",
      "11          0         0          [2217, 74, 1531, 2, 0, 11018]\n",
      "12          0         0   [29480, 1342, 1243, 748, 12138, 571]\n",
      "13          0         0          [4031, 2, 0, 267, 338, 20614]\n",
      "14          0         0      [329, 33976, 101, 29480, 1342, 2]\n",
      "15          0         0      [0, 12963, 600, 4157, 12138, 571]\n",
      "16          0         0                  [4031, 4108, 1717, 2]\n",
      "17          1         9      [0, 9713, 21179, 282, 25484, 885]\n",
      "18          1         9           [438, 4401, 625, 2, 0, 9713]\n",
      "19          1         9  [22053, 438, 3314, 29480, 1342, 1243]\n",
      "20          1         9        [1831, 2, 0, 9713, 13418, 6695]\n",
      "21          1         9       [607, 5, 21381, 11107, 12138, 2]\n",
      "22          1         9     [0, 9713, 22053, 438, 3314, 29480]\n",
      "23          1         9         [1342, 1243, 1831, 2, 0, 9713]\n",
      "24          1         9   [3023, 139, 1215, 40693, 1215, 1747]\n",
      "25          1         9            [386, 2, 0, 2716, 213, 905]\n",
      "26          1         9       [213, 29480, 1342, 1243, 164, 2]\n",
      "27          1         9        [0, 571, 19864, 821, 7043, 219]\n",
      "28          1         9         [748, 29480, 1342, 2, 0, 2977]\n",
      "29          1         9         [12138, 449, 7474, 3785, 2, 1]\n",
      "30          1         9          [1, 1, 0, 20982, 1034, 29480]\n",
      "31          1         9           [1342, 1243, 339, 914, 2, 1]\n",
      "32          1         9     [0, 9713, 29227, 1506, 8310, 4494]\n",
      "33          1         9                 [3144, 3055, 20782, 2]\n"
     ]
    }
   ],
   "source": [
    "def split_into_pieces(arr, piece_size=6):\n",
    "    arr = arr[:len(arr) - (len(arr) % piece_size)]\n",
    "    return [arr[i:i + piece_size] for i in range(0, len(arr), piece_size)]\n",
    "\n",
    "df_g['Tweet'] = df_g['Tweet'].apply(split_into_pieces)\n",
    "df_g = df_g.explode('Tweet').reset_index(drop=True)\n",
    "print(\"4: \", df_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5:      EventType                                  Tweet\n",
      "0           0    [0, 9713, 45155, 808, 21033, 29480]\n",
      "1           0           [1342, 1243, 748, 2, 0, 523]\n",
      "2           0    [44303, 397, 1215, 86, 1056, 12138]\n",
      "3           0         [571, 2, 0, 9713, 45783, 1584]\n",
      "4           0     [39949, 21033, 720, 4773, 1962, 2]\n",
      "5           0    [0, 9713, 31420, 12589, 4651, 7485]\n",
      "6           0        [36940, 3495, 4550, 2, 0, 9713]\n",
      "7           0   [4191, 33369, 175, 1471, 748, 12138]\n",
      "8           0         [157, 2, 0, 9713, 4191, 33369]\n",
      "9           0        [175, 1471, 748, 12138, 157, 2]\n",
      "10          0      [0, 298, 9877, 29480, 1342, 1243]\n",
      "11          0          [2217, 74, 1531, 2, 0, 11018]\n",
      "12          0   [29480, 1342, 1243, 748, 12138, 571]\n",
      "13          0          [4031, 2, 0, 267, 338, 20614]\n",
      "14          0      [329, 33976, 101, 29480, 1342, 2]\n",
      "15          0      [0, 12963, 600, 4157, 12138, 571]\n",
      "16          0                  [4031, 4108, 1717, 2]\n",
      "17          1      [0, 9713, 21179, 282, 25484, 885]\n",
      "18          1           [438, 4401, 625, 2, 0, 9713]\n",
      "19          1  [22053, 438, 3314, 29480, 1342, 1243]\n",
      "20          1        [1831, 2, 0, 9713, 13418, 6695]\n",
      "21          1       [607, 5, 21381, 11107, 12138, 2]\n",
      "22          1     [0, 9713, 22053, 438, 3314, 29480]\n",
      "23          1         [1342, 1243, 1831, 2, 0, 9713]\n",
      "24          1   [3023, 139, 1215, 40693, 1215, 1747]\n",
      "25          1            [386, 2, 0, 2716, 213, 905]\n",
      "26          1       [213, 29480, 1342, 1243, 164, 2]\n",
      "27          1        [0, 571, 19864, 821, 7043, 219]\n",
      "28          1         [748, 29480, 1342, 2, 0, 2977]\n",
      "29          1         [12138, 449, 7474, 3785, 2, 1]\n",
      "30          1          [1, 1, 0, 20982, 1034, 29480]\n",
      "31          1           [1342, 1243, 339, 914, 2, 1]\n",
      "32          1     [0, 9713, 29227, 1506, 8310, 4494]\n",
      "33          1                 [3144, 3055, 20782, 2]\n"
     ]
    }
   ],
   "source": [
    "df_g = df_g[['EventType', 'Tweet']]\n",
    "print(\"5: \", df_g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
