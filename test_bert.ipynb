{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPa4TUyuRH4TxsKwqkhqUFE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isaigordeev/sedt/blob/main/test_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6gePYLXKjBN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, Trainer, TrainingArguments\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataset_test = [] #данные от Алены\n",
        "dataset_train = [] #данные от Алены\n",
        "\n",
        "# Преобразование данных и создание DataLoader для тестового набора\n",
        "dataset_test = np.array(dataset_test).reshape(-1, 3)  # Преобразование формы\n",
        "dataset_test_tensor = torch.tensor(dataset_test, dtype=torch.float32)  # Преобразуем в тензор\n",
        "dataloader_test = DataLoader(TensorDataset(dataset_test_tensor), batch_size=8, shuffle=True)\n",
        "# Преобразование данных и создание DataLoader для тренировочного набора\n",
        "dataset_train = np.array(dataset_train).reshape(-1, 3)  # Преобразование формы\n",
        "dataset_train_tensor = torch.tensor(dataset_train, dtype=torch.float32)  # Преобразуем в тензор\n",
        "dataloader_train = DataLoader(TensorDataset(dataset_train_tensor), batch_size=8, shuffle=True)\n",
        "\n",
        "\n",
        "# Определение кастомной модели с несколькими линейными слоями\n",
        "class BertForBinaryClassification(BertPreTrainedModel):\n",
        "    def __init__(self, config, classifier_hidden_sizes=[256]):\n",
        "        super(BertForBinaryClassification, self).__init__(config)\n",
        "\n",
        "        self.bert = BertModel(config)\n",
        "\n",
        "        # Создаем список слоев классификатора на основе переданных гиперпараметров\n",
        "        classifier_layers = []\n",
        "        input_size = config.hidden_size\n",
        "\n",
        "        for hidden_size in classifier_hidden_sizes:\n",
        "            classifier_layers.append(nn.Linear(input_size, hidden_size))\n",
        "            classifier_layers.append(nn.ReLU())\n",
        "            classifier_layers.append(nn.Dropout(config.hidden_dropout_prob))\n",
        "            input_size = hidden_size\n",
        "\n",
        "        classifier_layers.append(nn.Linear(input_size, 1))\n",
        "        self.classifier = nn.Sequential(*classifier_layers)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None):\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "\n",
        "        pooled_output = outputs.pooler_output\n",
        "        logits = self.classifier(pooled_output)\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.BCEWithLogitsLoss()\n",
        "            # Преобразуем метки в тип float и изменяем размерность\n",
        "            labels = labels.float().view(-1, 1)\n",
        "            loss = loss_fct(logits, labels)\n",
        "\n",
        "        output = (probs,) + outputs[2:]\n",
        "        return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "# Инициализация модели\n",
        "from transformers import BertConfig\n",
        "config = BertConfig.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Определение гиперпараметров классификатора\n",
        "classifier_hidden_sizes = [512, 256, 128]\n",
        "\n",
        "model = BertForBinaryClassification(\n",
        "    config,\n",
        "    classifier_hidden_sizes=classifier_hidden_sizes\n",
        ")\n",
        "\n",
        "# Заморозка всех слоев BERT, кроме последнего линейного слоя\n",
        "for param in model.bert.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model.bert.encoder.layer[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Настройка параметров обучения\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    logging_dir='./logs',\n",
        ")\n",
        "\n",
        "# Инициализация тренера\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset_train,\n",
        "    eval_dataset=dataset_test,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.evaluate()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "dataset_test = [] #данные от Алены\n",
        "dataset_train = [] #данные от Алены\n",
        "\n",
        "# Преобразование данных и создание DataLoader для тестового набора\n",
        "dataset_test = np.array(dataset_test).reshape(-1, 3)  # Преобразование формы\n",
        "dataset_test_tensor = torch.tensor(dataset_test, dtype=torch.float32)  # Преобразуем в тензор\n",
        "dataloader_test = DataLoader(TensorDataset(dataset_test_tensor), batch_size=8, shuffle=True)\n",
        "# Преобразование данных и создание DataLoader для тренировочного набора\n",
        "dataset_train = np.array(dataset_train).reshape(-1, 3)  # Преобразование формы\n",
        "dataset_train_tensor = torch.tensor(dataset_train, dtype=torch.float32)  # Преобразуем в тензор\n",
        "dataloader_train = DataLoader(TensorDataset(dataset_train_tensor), batch_size=8, shuffle=True)\n",
        "\n",
        "\n",
        "# Инициализация модели\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels=2\n",
        ")\n",
        "\n",
        "# Заморозка всех слоев BERT, кроме последнего линейного слоя\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model.encoder.layer[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Настройка параметров обучения\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    logging_dir='./logs',\n",
        "    dataloader_shuffle=True,\n",
        ")\n",
        "\n",
        "# Инициализация тренера\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataloader_train,\n",
        "    eval_dataset=dataloader_test,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.evaluate()\n"
      ],
      "metadata": {
        "id": "uNBvsVw5Vx8p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}